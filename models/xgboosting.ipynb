{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "#Load data\n",
    "df = pd.read_csv(os.path.abspath(\"../data/normalized_labeled_training_data.csv\"))\n",
    "\n",
    "#Select all columns except the last\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "#Create new features\n",
    "X['day_or_night'] = X['hour_of_day'].apply(lambda x: 1 if 8 <= x < 21 else 0)\n",
    "\n",
    "X['normal_day'] = (~((X['summertime'] == 1) | (X['holiday'] == 1) | (X['weekday'] == 0))).astype(int)\n",
    "\n",
    "X['cold'] = X['temp'].apply(lambda x: 1 if x <= 8 else 0)\n",
    "\n",
    "#Remove bad features\n",
    "X = X.drop(['snow', 'snowdepth', 'holiday', 'visibility', 'precip', 'dew'], axis=1)\n",
    "\n",
    "#Select target column\n",
    "y = df['increase_stock']\n",
    "\n",
    "#stratify split, gör så att andelen negativt och positivt är densamma som hela datasettet \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    random_state=seed,\n",
    "    #use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3125 candidates, totalling 15625 fits\n",
      "Best Parameters: {'colsample_bytree': np.float64(0.5), 'learning_rate': np.float64(0.105), 'max_depth': np.int64(9), 'min_child_weight': np.int64(3), 'subsample': np.float64(0.625)}\n",
      "Best F1-Weighted Score: 0.8989\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': list(np.linspace(3, 15, num=5, dtype=int)),        # Tree depth, (if too low -> overfitting)\n",
    "    'min_child_weight': list(np.linspace(1, 10, num=5, dtype=int)), # Minimum child weight, (if too low -> overfitting)\n",
    "    'subsample': list(np.linspace(0.5, 1.0, num=5)),               \n",
    "    'colsample_bytree': list(np.linspace(0.5, 1.0, num=5)),        \n",
    "    'learning_rate': list(np.linspace(0.01, 0.2, num=5)),       \n",
    "    # 'gamma': list(np.linspace(0, 1, num=5)),                       \n",
    "    # 'n_estimators': list(np.linspace(50, 200, num=4, dtype=int)),  \n",
    "    # 'reg_alpha': [0, 0.01, 0.1, 1],                               \n",
    "    # 'reg_lambda': [0, 0.01, 0.1, 1],                               \n",
    "    # 'scale_pos_weight': [1, 2, 3]                                      \n",
    "}\n",
    "\n",
    "scoring = [\n",
    "    'f1_weighted',\n",
    "    'accuracy',\n",
    "    'recall_weighted',\n",
    "    'precision_weighted',\n",
    "    'roc_auc'\n",
    "]\n",
    "\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,           \n",
    "    refit='f1_weighted',       \n",
    "    cv=5,                      \n",
    "    n_jobs=-1,                \n",
    "    verbose=3,                 \n",
    "    return_train_score=False  \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and scores\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best F1-Weighted Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9208\n",
      "Test F1-Weighted: 0.9189\n",
      "Test Recall-Weighted: 0.9208\n",
      "Test Precision-Weighted: 0.9182\n",
      "Test ROC AUC: 0.9396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95       394\n",
      "         1.0       0.82      0.72      0.77        86\n",
      "\n",
      "    accuracy                           0.92       480\n",
      "   macro avg       0.88      0.84      0.86       480\n",
      "weighted avg       0.92      0.92      0.92       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Test F1-Weighted: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Test Recall-Weighted: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Test Precision-Weighted: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot feature importance\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mplot_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      6\u001b[0m plot_importance(model, importance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_gain\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\plotting.py:88\u001b[0m, in \u001b[0;36mplot_importance\u001b[1;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, values_format, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install matplotlib to plot importance\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(booster, XGBModel):\n\u001b[1;32m---> 88\u001b[0m     importance \u001b[38;5;241m=\u001b[39m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_score(\n\u001b[0;32m     89\u001b[0m         importance_type\u001b[38;5;241m=\u001b[39mimportance_type, fmap\u001b[38;5;241m=\u001b[39mfmap\n\u001b[0;32m     90\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(booster, Booster):\n\u001b[0;32m     92\u001b[0m     importance \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39mget_score(importance_type\u001b[38;5;241m=\u001b[39mimportance_type, fmap\u001b[38;5;241m=\u001b[39mfmap)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:805\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[1;32m--> 805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[1;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "plot_importance(model) \n",
    "plot_importance(model, importance_type='total_gain') \n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600 entries, 0 to 1599\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   hour_of_day  1600 non-null   float64\n",
      " 1   day_of_week  1600 non-null   float64\n",
      " 2   month        1600 non-null   float64\n",
      " 3   holiday      1600 non-null   float64\n",
      " 4   weekday      1600 non-null   float64\n",
      " 5   summertime   1600 non-null   float64\n",
      " 6   temp         1600 non-null   float64\n",
      " 7   dew          1600 non-null   float64\n",
      " 8   humidity     1600 non-null   float64\n",
      " 9   precip       1600 non-null   float64\n",
      " 10  snow         1600 non-null   float64\n",
      " 11  snowdepth    1600 non-null   float64\n",
      " 12  windspeed    1600 non-null   float64\n",
      " 13  cloudcover   1600 non-null   float64\n",
      " 14  visibility   1600 non-null   float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 187.6 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125\n"
     ]
    }
   ],
   "source": [
    "print(5**5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
